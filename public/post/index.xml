<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Eugene</title>
        <link>http://localhost:1313/post/</link>
        <description>Recent content in Posts on Eugene</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Mon, 21 Apr 2025 19:57:54 +0800</lastBuildDate><atom:link href="http://localhost:1313/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>考研经验分享贴</title>
        <link>http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/</link>
        <pubDate>Mon, 21 Apr 2025 19:57:54 +0800</pubDate>
        
        <guid>http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/</guid>
        <description>&lt;h1 id=&#34;考研经验分享&#34;&gt;考研经验分享：
&lt;/h1&gt;
&lt;h2 id=&#34;个人考后感受真实&#34;&gt;个人考后感受（真实）：
&lt;/h2&gt;
&lt;p&gt;先说一下我的整个的流程：我大概是4月份左右开的，一开始一直想着多手抓，其实最后还是把大量的精力放在学习量子力学上，后来到5-6月份，准备期末考试（热力学与统计物理，固体物理，量子力学真恐怖）以及报南方科技大学夏令营（这里后面会有提及），从夏令营回来之后，我一腔热血的开始准备考研了，但是准备了1个月左右买，就觉得学校吃的不行，睡觉也睡的不太好，所以在8月份我就回家复习备考；在家复习备考的过程就是普物和量子两手抓。后来在8月中旬我又去参加了上海大学的夏令营，在那里认识了我现在这个导师胡晓老师。直到9月份，我回学校之后才算是真正收心准备考研（目标是上海大学的物理学），这时还有100多天，最后初试有惊无险的通过了，复试也算是正常发挥，没有辜负这么多人的期待和我不到4月的努力吧。这就是我整个考研的过程，看起来还是挺丰富的吧，其实总结起来，考研并不难，难在你怎么做出适合你的选择？&lt;/p&gt;
&lt;h2 id=&#34;择校选方向&#34;&gt;择校(选方向)
&lt;/h2&gt;
&lt;p&gt;这里我觉得这个是整个考研过程中最重要的,正所谓“选择大于努力”,所以如果能够提前做出正确的选择,基本上就已经成功了一半.那么怎么样才算成功呢?或者说适合自己呢?&lt;/p&gt;
&lt;p&gt;首先,如果你的底子不好,并且没有啥比赛经验,我建议你选择一些常年招生人数多的学校(211,双非,末流985).因为这样你可以有足够的时间打基础,看自己喜欢研究什么方向,给自己留试错的空间,基础也是你之后做研究的根本,你可以选择考985,当然这是具有挑战的,但是也还是有许多先例的,但是有没有必要呢?(这个问题问一问你自己,如果觉得有必要,那就没必要往下看了,考985,如果你是抱着说我考上研究生就会舒服,我能告诉你,社会阶级只会越来越卷,找到适合自己的路比这么一个虚无缥缈的title更有价值).&lt;/p&gt;
&lt;p&gt;然后,底子还算好,但是没有啥比赛经验的,我建议你问一下其他学长(笑).&lt;/p&gt;
&lt;p&gt;最后,有比赛经验的同学,你们可以往上冲985,因为我相信你们有这份勇气和毅力(并不是说前面的人没有这些,只不过他们把握住了这样的机会).但是还请你们斟酌再三,你们都是有勇气,有毅力,我相信你们能够很好坚持考研的这些事,方向对你们来说也很重要.如果你上了一个985,最后只能做你不喜欢的方向,这并不是一个好的结果.所以提前了解你想考的学校,然后根据你的本科成绩排名以及比赛获奖的情况去报对应学校的夏令营(具体可以找我,但是其实就是海投,不要怕麻烦,或者说怕自己是双非怎么怎么样,又或者没有保研资格).&lt;/p&gt;
&lt;h2 id=&#34;英语&#34;&gt;英语:
&lt;/h2&gt;
&lt;p&gt;我考研英语:50分.我发挥的不太好,但是这是有原因的,我并没有认真对待它&amp;mdash;单词没有认真背,真题没有认真复盘.但是,经过了这么久英语的学习,我还是觉得&lt;strong&gt;看美剧&lt;/strong&gt;真的有效果(如果有需要可以找我下资源).通过看美剧,我在复试的时候和一个老师用英文单聊了3min左右.整个英语应该是&lt;strong&gt;每天短时间和长战线&lt;/strong&gt;(持续很久).&lt;/p&gt;
&lt;h2 id=&#34;量子力学&#34;&gt;量子力学:
&lt;/h2&gt;
&lt;p&gt;我的量子力学是:127分.量子力学可以说我是学了3遍吧,第一遍是跟着&lt;strong&gt;陈童老师的课&lt;/strong&gt;学,第二遍是自学Griffith(跟着陈童老师同步学习),第三遍是MIT的Quantum Mechanic(&lt;a class=&#34;link&#34; href=&#34;https://ocw.mit.edu/courses/8-05-quantum-physics-ii-fall-2013/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://ocw.mit.edu/courses/8-05-quantum-physics-ii-fall-2013/&lt;/a&gt;)这个对于英语的需求很高,但是是一个很好的资源.我可以说量子力学是最需要时间的,也是最不需要时间的.前者是因为,要学好学懂很难,后者是因为如果你单纯是以考试为目的,就直接Justchan7和小黄书那一套也可以达成目的.&lt;/p&gt;
&lt;p&gt;至于&lt;strong&gt;做题&lt;/strong&gt;:我的小黄书没刷完(就前三章刷完了),Griffith的题我十分建议你去钻研,连续性很好(后面的题是前面的延伸).&lt;/p&gt;
&lt;p&gt;然后书籍的推荐:Griffith的量子力学导论但不局限于一本,什么书都可以去参考看看,但是要有目的性(要学什么东西).最后真题的话,最后一个月刷就可以了,到最后你做真题遇不到你做不出的题就差不多了.&lt;/p&gt;
&lt;h2 id=&#34;夏令营问题具体可以找我私聊最后有联系方式&#34;&gt;夏令营问题(具体可以找我私聊,最后有联系方式):
&lt;/h2&gt;
&lt;p&gt;对于夏令营,我应该算是参加的最多的那一个(但是不是最成功的那一个),所以我知道这个适合什么样的人群去参加:有比赛经验,且成绩排名还不错的同学,但是你报一下,万一进去了呢.我知道有很多人怕麻烦,所以我会和你说报夏令营的好处是什么?&lt;/p&gt;
&lt;p&gt;好处是:如果你进了夏令营,就算你没有保研资格,你到后面复试你也会更有优势,这里的优势指的是:你可以在复试的时候以一种更加自如的心态去面对老师,并且你可以提前了解老师的研究方向(我觉得没有一个老师会拒绝一个主动的学生,况且这个学生甚至在做一件可能没有什么回报的事).
说完这些&lt;strong&gt;直接的好处&lt;/strong&gt;,说一下&lt;strong&gt;间接&lt;/strong&gt;的:参加夏令营可以提高你的胆识,我一直觉得我们这个层级的学生和那些985,211的学生之间的差距(天赋,勇气),天赋我觉得无关紧要,更重要的是我们缺少这份勇气,每一个考研人都觉得考研就已经迈出了很大的一步,但是根据我所见过的名校的学生(985,剑桥),它们在本科期间就已经做了很多很多的事情,这里并不是说贬低我们自己,而是实事求是,我们每个人都在走我们自己的路,但是不妨出去看看,其他人是什么样子的,并且大方的表达自己,人生还很长,未来是不一定,没必要去争一个谁输谁赢,自己满意就好了.所以最后给自己一个成长的机会,无论结果如何,去试试.&lt;/p&gt;
&lt;p&gt;制作不易,希望有所帮助!&lt;/p&gt;
&lt;h2 id=&#34;书店&#34;&gt;书店:
&lt;/h2&gt;
&lt;p&gt;下面的书籍都是我考研过程中买的书,如果学弟学妹有需要的可以联系我(有一定收费,但一定更便宜很多):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;1&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/2.jpeg&#34;
	width=&#34;4032&#34;
	height=&#34;3024&#34;
	srcset=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/2_hu_6da003cdb3d72f7.jpeg 480w, http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/2_hu_8b8ba7334d3b8bc0.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;2&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/3.jpeg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;3&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/4.jpeg&#34;
	width=&#34;4032&#34;
	height=&#34;3024&#34;
	srcset=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/4_hu_5b5735cc3c4fb9ce.jpeg 480w, http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/4_hu_6ffd5f0701274e09.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;4&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/5.jpeg&#34;
	width=&#34;4032&#34;
	height=&#34;3024&#34;
	srcset=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/5_hu_efcd032ebe92690e.jpeg 480w, http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/5_hu_b15993a4a76271d6.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;5&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/6.jpeg&#34;
	width=&#34;4032&#34;
	height=&#34;3024&#34;
	srcset=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/6_hu_3cde0691ee3ebc7a.jpeg 480w, http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/6_hu_a7455589c2aba27c.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;6&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/7.jpeg&#34;
	width=&#34;4032&#34;
	height=&#34;3024&#34;
	srcset=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/7_hu_1d28518ce235fc32.jpeg 480w, http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/7_hu_2b0c50514e44812b.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;7&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/8.jpeg&#34;
	width=&#34;4032&#34;
	height=&#34;3024&#34;
	srcset=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/8_hu_3d86b397007ca501.jpeg 480w, http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/8_hu_6fcce7d60d2f08fa.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;8&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/9.jpeg&#34;
	width=&#34;4032&#34;
	height=&#34;3024&#34;
	srcset=&#34;http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/9_hu_952ed093ea9f6b4e.jpeg 480w, http://localhost:1313/2025/%E8%80%83%E7%A0%94%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E8%B4%B4/9_hu_bc0ddd0715593541.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;9&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;联系方式&#34;&gt;联系方式:
&lt;/h2&gt;
&lt;h3 id=&#34;qq1796784184&#34;&gt;QQ:1796784184
&lt;/h3&gt;
&lt;h3 id=&#34;wechat15970835051phone-number&#34;&gt;Wechat:15970835051(Phone Number)
&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;希望每一个考研的同学都可以顺利上岸,希望这篇文章可以帮助到你!&lt;/strong&gt;(如果有考&lt;strong&gt;上海大学&lt;/strong&gt;的可以直接联系我,我给你真题)&lt;/p&gt;
&lt;h3 id=&#34;版权信息&#34;&gt;版权信息
&lt;/h3&gt;
&lt;p&gt;本文原载于 &lt;a class=&#34;link&#34; href=&#34;https://quantum51.top&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;quantum51.top&lt;/a&gt;，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AI|Why Machines Learn?</title>
        <link>http://localhost:1313/2025/aiwhy-machines-learn/</link>
        <pubDate>Sat, 19 Apr 2025 09:34:28 +0800</pubDate>
        
        <guid>http://localhost:1313/2025/aiwhy-machines-learn/</guid>
        <description>&lt;h1 id=&#34;why-machines-learn&#34;&gt;Why machines learn？
&lt;/h1&gt;
&lt;h2 id=&#34;deseperatly-seeking-pattern&#34;&gt;Deseperatly seeking pattern
&lt;/h2&gt;
&lt;h3 id=&#34;从现象出发&#34;&gt;从现象出发
&lt;/h3&gt;
&lt;p&gt;这里面的pattern其实就是数据中某种模式特征，打个比方，每一个人对于每一年每一个季度的天气的理解和判断，都是基于一段时间（几年）的生活，通过观察每一年的天气（数据），然后得出一些经验（特征）。&lt;/p&gt;
&lt;p&gt;然而令人惊讶的是，小小的鸭苗在没有父母的帮助下，也可以从运动的物体中找到一定的规律，这些规律可以是相似之处，也可以是不同之处，比如，小鸭苗如果看见有5个黑鸭苗和2个白鸭苗的队伍，它会知道自己是黑的还是白的，并且知道黑色和白色的差别，最后他会加入到其中一个队伍里面。&lt;/p&gt;
&lt;p&gt;这就是令人惊讶的动物的学习能力。在早些年，就有科学家提出“动物（人）是怎么学习的”这一问题，他们就想到先从学习数据中的特征入手，于是就有科学家开发了Perceptron（感知机）来模拟人类的思考。当你给这个感知机下面这些数据的时候：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;$x_1$&lt;/th&gt;
          &lt;th&gt;$x_2$&lt;/th&gt;
          &lt;th&gt;$y$&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;4&lt;/td&gt;
          &lt;td&gt;2&lt;/td&gt;
          &lt;td&gt;8&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;2&lt;/td&gt;
          &lt;td&gt;5&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;5&lt;/td&gt;
          &lt;td&gt;10&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;4&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;我们只需要通过一点点的观察和心算就能够发现这组数据中存在的关系是：
$$
y = x_1+2x_2
$$&lt;/p&gt;
&lt;p&gt;而对于现在的机器而言无非就是一个Regression算法，这个算法的意思是：你给他很多的train data（有input和output），然后它会通过学习这些数据来给出这些量之间的线性关系（$y =w_1x_1+w_2x_2+b$），也就是学习得到 $w_1,w_2$(系数，weight)以及偏差（截距）。&lt;/p&gt;
&lt;p&gt;然后你可以通过一些测试数据来判读这一组系数的好坏（离最优的系数差多远，最优的系数当然是通过每一个数据点，但是实际上并不能很好的做到），最后得到这组数据的最优解，接下来你就可以通过这样的关系来predict不同的input，会有怎么样的output了。就好像天气一样，你可以通过之前每一天的数据来预测之后的数据一样，只不过天气与很多因素有关。&lt;/p&gt;
&lt;p&gt;所以Regression Method的具体步骤是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;给他一定的训练数据，并且指定一开始的 $w_1,w2，b$&lt;/li&gt;
&lt;li&gt;然后计算这一组的系数所给出的output $y_{predict}和y_{train}$之间的差距，然后通过这个差距反过来调节系数&lt;/li&gt;
&lt;li&gt;不断的执行，直到这个差距小到我们的要求为止&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;神经元的逻辑化&#34;&gt;神经元的逻辑化
&lt;/h3&gt;
&lt;p&gt;言归正传（Regression后面还会系统的说明），我们也许可以通过理解机器是怎么学习的来完全理解人类是怎么学习的（这里我的理解是我们可以在让机器逐步学会学习的过程中，不断地深化我们对于自己学习过程的理解）。&lt;/p&gt;
&lt;p&gt;19世纪，图灵等科学家就认为logic和computation之间有很深厚的联系，他们断言“所有的计算都可以被简化为某种逻辑”。然后就引出了这样一个问题：既然人脑是可以执行计算的，那么它是怎么样执行逻辑操作的（它底层是否像逻辑门一样呢？）。&lt;/p&gt;
&lt;p&gt;带着这样的问题，有生物学家通过类比一个神经元：&lt;img src=&#34;http://localhost:1313/2025/aiwhy-machines-learn/1.png&#34;
	width=&#34;948&#34;
	height=&#34;421&#34;
	srcset=&#34;http://localhost:1313/2025/aiwhy-machines-learn/1_hu_4cf4f3e353866372.png 480w, http://localhost:1313/2025/aiwhy-machines-learn/1_hu_f54ef82382b8a7c7.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;截屏2025-04-19 09.05.51&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;225&#34;
		data-flex-basis=&#34;540px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;图中Dendrites就是神经元的树突，它负责接受各种刺激，树突中间的就是细胞体，他可以处理树突接受到的刺激（相当于进行计算），然后Axon（轴突）负责转递细胞体的结果到Axon terminals（端粒），端粒在将这个结果传递给周边其他的神经元。&lt;/p&gt;
&lt;p&gt;然后生物学家希望把这一机构转化为一个简单的计算模型，理由是：他很像一个机器，你给他一个输入（刺激），他就会给输出。因此他们想要通过类比用神经元来构建逻辑AND，OR操作。&lt;/p&gt;
&lt;p&gt;他们首先将这个神经元定义为这个样子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/2025/aiwhy-machines-learn/2.png&#34;
	width=&#34;974&#34;
	height=&#34;382&#34;
	srcset=&#34;http://localhost:1313/2025/aiwhy-machines-learn/2_hu_5ca8c49f76992445.png 480w, http://localhost:1313/2025/aiwhy-machines-learn/2_hu_64a170845a1ba395.png 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;254&#34;
		data-flex-basis=&#34;611px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;上图的左侧就是给神经元的输入，然后中间的g，f就代表的是神经元对于输入的处理，然后再到右侧的输入y（其实我们可以在g，f的中间再加一个传输的过程，就是将g的处理结果传输到下一个f神经元处）。&lt;/p&gt;
&lt;p&gt;然后这里假设 $x_1，x_2 \in {0,1}$,并且神经元会这样处理输入：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Sum  = x1+x2&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If  $Sum\geq \theta :y=1$&lt;/p&gt;
&lt;p&gt;else:y = 0&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以这里我们就可以认为g其实就是对输入做了一个加法，而f函数就是对g的输出做了一个判断，但是这个 $\theta$要根据具体的情况而定的（这也是人脑的神秘之处），这一整个可以表示为：&lt;/p&gt;
&lt;p&gt;$$
f(g(x)) =
\begin{cases}0, &amp;amp; g(x) &amp;lt; \theta \\
1, &amp;amp; g(x) \geq \theta
\end{cases}
$$&lt;/p&gt;
&lt;p&gt;有了这样的前提，我们就可以来设计基础的布尔逻辑门的操作了。&lt;/p&gt;
&lt;p&gt;首先对于AND逻辑来说：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;x1&lt;/th&gt;
          &lt;th&gt;x2&lt;/th&gt;
          &lt;th&gt;sum&lt;/th&gt;
          &lt;th&gt;x1 And x2&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;2&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;我们可以看到这么一个逻辑对于Sum小于等于1的输出都是0，而大于1的就是1，所以我们要神经元完成这个逻辑只需要将 $\theta = 2$ ,得到：&lt;/p&gt;
&lt;p&gt;$$
f(g(x)) =
\begin{cases}0, &amp;amp; g(x) &amp;lt; 2 \\
1, &amp;amp; g(x) \geq 2
\end{cases}
$$&lt;/p&gt;
&lt;p&gt;对于OR逻辑操作也是同理，读者可以自行一试（答案是 $\theta=1$）。&lt;/p&gt;
&lt;p&gt;但是这里有一个比较有意思的问题：但神经元需要处理不同种类的逻辑的时候，他是如何调整这个 $\theta$的值呢？&lt;/p&gt;
&lt;p&gt;Tips:下次记得分段公式要三条斜杆（调试了一上午）&lt;/p&gt;
&lt;p&gt;本文原载于 &lt;a class=&#34;link&#34; href=&#34;https://quantum51.top&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;quantum51.top&lt;/a&gt;，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>毕业论文|chapter 2</title>
        <link>http://localhost:1313/2025/%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87chapter-2/</link>
        <pubDate>Wed, 16 Apr 2025 16:39:44 +0800</pubDate>
        
        <guid>http://localhost:1313/2025/%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87chapter-2/</guid>
        <description>&lt;h1 id=&#34;量子纠缠的验证&#34;&gt;量子纠缠的验证
&lt;/h1&gt;
&lt;h2 id=&#34;bell不等式&#34;&gt;Bell不等式
&lt;/h2&gt;
&lt;p&gt;要验证量子纠缠态的存在性，我们首先要证明隐变量理论的矛盾性，这样就证明了非局域性是量子力学的本质特征。前面EPR论文提出了量子力学的不完备性，而应该由额外的变量来补充的论据。这些变量试图去恢复理论中的局域性（&lt;strong&gt;一个系统上的测量结果不受过去与之相互作用且遥远系统的影响&lt;/strong&gt;）和因果性。在之后的一段时间里，有许多试图去完善隐变量理论的工作，但是均已失败告终。&lt;/p&gt;
&lt;p&gt;Bell通过将隐变量理论数学化并加入局域性假设，证明了其与量子力学的统计预测不相容（具有矛盾），即非局域性是量子力学的典型特征。&lt;/p&gt;
&lt;h3 id=&#34;斯特恩-格拉赫实验&#34;&gt;斯特恩-格拉赫实验
&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;（斯特恩-格拉赫实验可以展开说）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;考虑一对自旋为$\frac{1}{2}$的粒子，整个系统处于自旋单态（总自旋为0），两个粒子自由地朝反方向运动。自旋单态的表达式为：&lt;/p&gt;
&lt;p&gt;$$
\ket{\psi} = \frac{1}{\sqrt{2}}(\ket{\uparrow \downarrow} - \ket{\downarrow \uparrow})
$$&lt;/p&gt;
&lt;p&gt;式中$\ket{\uparrow\downarrow}$表示两粒子系统的状态，也可写成$\ket{\uparrow} \otimes \ket{\downarrow}$（左边为粒子1的自旋状态），$\ket{\uparrow}$表示单个粒子自旋向上，$\ket{\downarrow}$表示自旋向下。&lt;/p&gt;
&lt;p&gt;定义粒子1和2的自旋算符$\vec{\sigma_1}$和$\vec{\sigma_2}$（Pauli算符形式，自旋算符与Pauli算符的关系为$\vec{S} = \frac{\hbar}{2}\vec{\sigma}$）。通过斯特恩-格拉赫实验测量某个方向（例如$\vec{a}$为粒子1的测量方向）的自旋分量。&lt;/p&gt;
&lt;p&gt;测量粒子1的$\vec{\sigma_1} \cdot \vec{a}$可能得到$+1$或$-1$。由于系统反对称性（&lt;strong&gt;可补充解释&lt;/strong&gt;），此时测量粒子2的$\vec{\sigma_2} \cdot \vec{a}$结果必然与粒子1相反（$-1$或$+1$）。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;隐变量理论的数学化&#34;&gt;隐变量理论的数学化
&lt;/h3&gt;
&lt;p&gt;Bell通过以下两个假设引出隐变量原理：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;局域性假设&lt;/strong&gt;：若两粒子自旋的测量在空间分离的方向进行，则一个磁铁的方向（测量粒子1的方向）不会影响另一个磁铁的测量结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;因果性假设&lt;/strong&gt;：通过测量$\sigma_1$的某个方向分量，可预测对应方向粒子2的自旋分量结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;假设1指定了隐变量理论的局域性；假设2说明测量结果可被提前预测，对应隐变量$\lambda$的存在性（$\lambda$可以是单变量、一组变量或函数）。测量结果满足：&lt;/p&gt;
&lt;p&gt;$$
A(\vec{a}, \lambda) = \pm 1, \quad B(\vec{b}, \lambda) = \pm 1
$$&lt;/p&gt;
&lt;p&gt;隐变量理论的期望值为：&lt;/p&gt;
&lt;p&gt;$$
P(\vec{a}, \vec{b}) = \int d\lambda , \rho(\lambda) A(\vec{a}, \lambda) B(\vec{b}, \lambda)
$$&lt;/p&gt;
&lt;p&gt;而量子力学对自旋单态的期望值为：&lt;/p&gt;
&lt;p&gt;$$
\langle \vec{\sigma}_1 \cdot \vec{a} ; \vec{\sigma}_2 \cdot \vec{b} \rangle = -\vec{a} \cdot \vec{b}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;主要证明&#34;&gt;主要证明
&lt;/h3&gt;
&lt;p&gt;Bell不等式的推导步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;归一化条件&lt;/strong&gt;：$\int d\lambda , \rho(\lambda) = 1$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;测量结果限制&lt;/strong&gt;：$A(\vec{a}, \lambda), B(\vec{b}, \lambda) = \pm 1$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;引入新方向$\vec{c}$&lt;/strong&gt;，计算差值：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
P(\vec{a}, \vec{b}) - P(\vec{a}, \vec{c}) = \int d\lambda , \rho(\lambda) A(\vec{a}, \lambda) A(\vec{b}, \lambda) \left[ A(\vec{b}, \lambda) A(\vec{c}, \lambda) - 1 \right]
$$&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;取绝对值并利用积分性质&lt;/strong&gt;，最终得到Bell不等式：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$$
|P(\vec{a}, \vec{b}) - P(\vec{a}, \vec{c})| \leq 1 + P(\vec{b}, \vec{c})
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;验证实例&#34;&gt;验证实例
&lt;/h3&gt;
&lt;p&gt;取$\vec{a} = (0,0,1)$, $\vec{b} = (1,0,0)$, $\vec{c} = (1/\sqrt{2}, 0, 1/\sqrt{2})$：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$P(\vec{a}, \vec{b}) = 0$&lt;/li&gt;
&lt;li&gt;$P(\vec{a}, \vec{c}) = -1/\sqrt{2}$&lt;/li&gt;
&lt;li&gt;$|P(\vec{a}, \vec{b}) - P(\vec{a}, \vec{c})| = 1/\sqrt{2} \approx 0.707$&lt;/li&gt;
&lt;li&gt;$1 + P(\vec{b}, \vec{c}) = 1 - 1/\sqrt{2} \approx 0.293$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;显然$0.707 &amp;gt; 0.293$，违反Bell不等式，说明隐变量理论无法解释量子力学预测。
$$
f(g(x)) =
\begin{cases}
0, &amp;amp; g(x) &amp;lt; 2 \
1, &amp;amp; g(x) \geq 2
\end{cases}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;结论&#34;&gt;结论
&lt;/h3&gt;
&lt;p&gt;通过证明Bell不等式在量子力学中不成立，表明非局域性是量子力学的本质特征，从而验证了量子纠缠的合理性。&lt;/p&gt;
&lt;h2 id=&#34;chsh游戏&#34;&gt;CHSH游戏：
&lt;/h2&gt;
&lt;p&gt;上面描述了两种可行的实验方案，但是其实还有一种更容易理解的思想实验（CHSH游戏），通过这个游戏的分析表明任何经典的局部隐变量理论都不能够解释量子纠缠的情况。由于该游戏确实在物理上可实现，因此就证明了经典物理从根本上无法解释某些量子现象，至少在“局部”层面上无法解释。&lt;/p&gt;
&lt;h3 id=&#34;chsh游戏的定义&#34;&gt;CHSH游戏的定义:
&lt;/h3&gt;
&lt;p&gt;游戏有三个人,一个Alice,一个Bob,一个裁判:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先,**裁判以均匀的概率随机地选定两个数 $x，y\in {0,1}$&lt;/li&gt;
&lt;li&gt;然后，裁判把 $x$给Alice，$y$给Bob&lt;/li&gt;
&lt;li&gt;最后，Alice$需要给出回应a \in {0,1}$,Bob也需要给出回应$b\in{0,1}$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果$x = y = 1$，则只有当Alice和Bob要给出不一样的回应才可以获胜；对于其他的情况，则需要Alice和Bob的回应一样才能获胜。&lt;/p&gt;
&lt;h3 id=&#34;经典情况&#34;&gt;经典情况：
&lt;/h3&gt;
&lt;p&gt;在经典情况下，如果我们去找一个对于这个游戏的最优策略，那么只需要找到胜率最高的那种策略，根据下面的分析：&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;$x$&lt;/th&gt;
          &lt;th&gt;$y$&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;最佳的&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;$a和b相同$&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;$a和b相同$&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;$a和b相同$&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;$a和b不同$&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;我们可以从上面的表格看到，有三种情况都需要Alice和Bob选择一样的回应，所以对于经典的最优解就是：Alice和Bob两者的回应保持相同，则获胜的概率最大为 $\frac{3}{4}$（对于这种策略，四种情况只有一种情况输）。&lt;/p&gt;
&lt;h3 id=&#34;量子情况&#34;&gt;量子情况：
&lt;/h3&gt;
&lt;p&gt;对于量子情况，首先介绍一些对于量子比特和量子态的基础知识。&lt;/p&gt;
&lt;h4 id=&#34;基态&#34;&gt;基态：
&lt;/h4&gt;
&lt;p&gt;让$s_1\dots s_n \in {0,1}^n$是一个长度为n的二进制串，$i\in {0,1,\dots,2^{n}-1}$是对应二进制串的值，比如n=2，那么此时二进制串为$s_1s_2={00,01,10,11}$,对应这四个二进制串的值为0,1,2,3。然后根据这个我们可以定义 $\ket{s_1\dots s_n}$是一个长度为 $2^n$的向量，假设这个向量里面的二进制串所对应的值为 $i$，则这个向量的第 $i+1$个位置为1，其余的位置为0，这个向量$\ket{s_1\dots s_n}$我们就称之为n个量子比特的基态。对于n=2(两个量子比特)的情况，那么就有 $\ket{00},\ket{01},\ket{10,\ket{11}}$这些基态，这些基态分别对应(下面的基态都是列向量）：
$$
\ket{00}=[1,0,0,0]^T，\ket{01}=[0,1,0,0]^T \\
\ket{10}=[0,0,1,0]^T，\ket{11}=[0,0,0,1]^T
$$&lt;/p&gt;
&lt;h5 id=&#34;量子态&#34;&gt;量子态：
&lt;/h5&gt;
&lt;p&gt;定义：n个量子比特的量子态是一个向量 $\vec{x}$:
$$
\vec{x} = x_{0\dots0}\ket{0\dots0}+ \dots + x_{1\dots1}\ket{1\dots1} \\
= \sum_{S\in{0,1}^n}x_s\ket{S}
$$
上式中 $S$是遍历所有长度是n的二进制串，并且 $\vec{x}$满足归一化条件：
$$
|x_{0\ldots0}|^2 + \cdots + |x_{1\ldots1}|^2 = 1.
$$&lt;/p&gt;
&lt;p&gt;系数 $x_{0\dots0},\dots,x_{1\dots1}$可以是复数，但是我们只考虑它们是实数的情况。&lt;/p&gt;
&lt;h5 id=&#34;量子门&#34;&gt;量子门：
&lt;/h5&gt;
&lt;p&gt;就像函数  $f(x)$一样，有输出对应着输入，这个函数相当于对这个输入做了某种操作；那么对应某个系统的量子态，我们应该如何去操作它改变它呢？上面我们提到了量子态是一个向量 $\vec{x}$,那么量子门操作就是 $f(\vec{x})$,并且要遵循如下的性质：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;归一化：对于所有满足归一化条件的 $\vec{x}$，在经过量子门操作之后的量子态 $\vec{y}=f(\vec{x})$也要满足归一化关系。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;线性操作（可以在附录说一下为什么线性是必要的）&lt;!--Problem7--&gt;：对于所有的可能的输入的向量 $\vec{a}，\vec{b}$以及所有实数 $c$，我们有 $f(\vec{a}+\vec{b})=f(\vec{a})+f({\vec{b}})$和 $f(c\vec{a})=cf(\vec{a})$.&lt;/p&gt;
&lt;p&gt;对于满足上面两个性质的量子门操作，我们称之为线性量子门。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;量子系统孤立系统&#34;&gt;量子系统，孤立系统：
&lt;/h4&gt;
&lt;p&gt;对于要如何去实现这样的二进制的量子态我们可以直接想到的是电子，我们可以依靠电子的自旋量子数是1/2的特性（这个特性使得电子再任意方向上的自旋都有两个本征态，自旋向上，自旋向下）去实现基态是 $\ket{0},\ket{1}$的量子系统。顺着这个思路，我们可以得出量子系统其实就是多个有顺序的电子的集合表示为 $E =(e_1,\dots,e_n)$。&lt;/p&gt;
&lt;p&gt;因为每个电子要么自旋向上（0）要么自旋向上（1），所以这个量子系统的状态一定是二进制串 $S = s_1\dots s_n\in{0,1}^n$中的一个，那么我们可以将测量这个量子系统中每一个电子的自旋的过程描述为 $E \to S$&lt;/p&gt;
&lt;p&gt;在大部分情况下，我们只关心庞大世界中的某一个系统，那么此时这个孤立系统是怎么样的，和复合系统的区别是什么？一个孤立的量子系统 $E$之所以孤立是因为他的测量事件和其他量子系统的测量是独立的，即：&lt;/p&gt;
&lt;p&gt;这个孤立系统的测量事件：$E \to S$与所有其他的系统的测量 $E’ \to S&amp;rsquo;$是独立的，也就是这个系统的测量结果并不会影响其他系统的结果。&lt;/p&gt;
&lt;p&gt;上面我们提到了测量事件和测量结果，那么对于一个处于某一个量子态的量子系统E，这些是如何定义的呢？&lt;/p&gt;
&lt;h5 id=&#34;测量公理&#34;&gt;测量公理：
&lt;/h5&gt;
&lt;p&gt;假设 $E$是一个由n个电子 $(e_1,\dots,e_n)$ 组成的孤立量子系统，根据前面的定义，我们可以用一个向量 $\vec{x}$来表示这个系统的状态，如果我们去测量这个系统的状态，可能的结果是所有二进制串（长度为n） $S\in{0,1}^n$中的一个，或者说这个系统的状态是不同基态的组合：
$$
\ket{\psi} = \sum_{S\in{0,1}^n}x_s\ket{S}
$$
那么此时我们知道当我们观测这个系统的时候，这个系统一定会处于基态中的一个，但是在观测前我们也许可以知道我们测量得到不同基态的概率 $|x_s|^2$,测量公理定义了这样的概率是：
$$
Pr [E \to S] =|x_s|^2
$$
以及将我们可能对这个处于 $\vec{x}$ 孤立系统E做出的物理操作定义为一个量子门 $f$，这样就使得前面有关与量子门的操作和定义能够在实际物理世界中存在对应。&lt;/p&gt;
&lt;p&gt;总而言之，这个公理将一个孤立的系统描述为某一个量子态，以及每一个物理上的操作（Physical process）描述为某一个量子门。&lt;/p&gt;
&lt;h4 id=&#34;张量积tensor-product&#34;&gt;张量积（Tensor Product）：
&lt;/h4&gt;
&lt;p&gt;回想一下我们CHSH游戏中指定了Alice和Bob共享一个EPR对 $\ket{\psi}=\frac{1}{\sqrt{2}}(\ket{00}+\ket{11})$,那么这个状态其实是Alice的电子和Bob的电子相组合成的系统（但是这个两个系统之间有纠缠）。前面我们知道对于一个系统的状态可以用一个向量 $\vec{x}=(x_1,\dots,x_n)^T$（长度为n）来描述，如果此时还有另一个系统状态是 $\vec{y}=(y_1,\dots,y_m)^T$（长度为m），那么两个系统组合起来的状态由向量 $\vec{\Phi}$  表示，那么这个向量应该如何定义呢？&lt;/p&gt;
&lt;h5 id=&#34;向量的张量积&#34;&gt;向量的张量积：
&lt;/h5&gt;
&lt;p&gt;我们这里引入向量之间的张量积，定义为：
$$
\vec{\Phi} = \vec{x}\otimes\vec{y}
$$
并且这个向量 $\vec{\Phi}$的长度是nm，并且 $\otimes$被称之为张量积。向量$\vec{x}$和向量$\vec{y}$之间的张量积定义为：
$$
\vec{x}\otimes\vec{y} = (a_1b_1,a_1b_2,\dots,a_nb_{n-1},a_nb_n
$$
比如，但两个系统（$E_1，E_2$）的状态分别为 $\vec{a}=(a_1,a_2)$和 $\vec{b}=(b_1,b_2,b_3)$，那么这两个系统组合的状态 $\vec{\psi}$为：
$$
\vec{\psi}=\vec{a}\otimes \vec{b}=[a_1(b_1,b_2,b_3),a_2(b_1,b_2,b_3)] \\
=(a_1b_1,a_1b_2,a_1b_3,a_2b_1,a_2b_2,a_2b_3)
$$&lt;/p&gt;
&lt;h5 id=&#34;不同孤立系统状态的张量积&#34;&gt;不同孤立系统状态的张量积：
&lt;/h5&gt;
&lt;p&gt;上面对于两个系统组合起来的张量积表示有一个前提条件就是，它们两个都是孤立系统，即它们不能有相互作用或者纠缠（如EPR态）。它表述为一个定理：&lt;/p&gt;
&lt;p&gt;如果两个系统 $E_1$和 $E_2$都是孤立的系统，并且两个分别由向量 $\vec{x}$和$\vec{y}$表示，则它们的联合系统状态 $E_1E_2$ 用向量 $\vec{x}\otimes\vec{y}$表示&lt;/p&gt;
&lt;h5 id=&#34;作用在两个系统的量子门的张量积&#34;&gt;作用在两个系统的量子门的张量积：
&lt;/h5&gt;
&lt;p&gt;我们已经定义了两个孤立系统的联合状态是怎么样的，那么我们想，如果我们想对系统（A和B）进行物理操作（相当于作用量子门）,那么这些操作是如何影响整个系统的联合状态的呢？我们可以定义：&lt;/p&gt;
&lt;p&gt;让 $f：V^n\to V^n$表示对于系统A的一个线性操作（线性的量子门），$g:V^m\to V^m$表示对于系统B的一个线性操作，则对于这整个系统的联合状态 $\vec{a}\otimes\vec{b}$而言，我们对于整个系统的操作 $f\otimes g$作用效果为：
$$
(f\otimes g)(\vec{a}\otimes\vec{b}) = f(\vec{a})\otimes g(\vec{b})
$$
这里对于整个系统AB的操作 $f\otimes g$ 可以由一个公理指定（$f$作用与A系统，$g$作用于B系统）。（&lt;strong&gt;此处可以说明一下这里如果两个操作并不同时发生，这个定义还是有效的吗？，因为两个系统是孤立系统，所以互不影响。&lt;/strong&gt;）&lt;/p&gt;
&lt;h4 id=&#34;chsh游戏的一种解法&#34;&gt;CHSH游戏的一种解法：
&lt;/h4&gt;
&lt;h2 id=&#34;附录&#34;&gt;附录
&lt;/h2&gt;
&lt;h3 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h3&gt;
&lt;h3 id=&#34;版权信息&#34;&gt;版权信息
&lt;/h3&gt;
&lt;p&gt;本文原载于 &lt;a class=&#34;link&#34; href=&#34;https://quantum51.top&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;quantum51.top&lt;/a&gt;，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>毕业论文|chapter 1</title>
        <link>http://localhost:1313/2025/%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87chapter-1/</link>
        <pubDate>Wed, 16 Apr 2025 16:38:41 +0800</pubDate>
        
        <guid>http://localhost:1313/2025/%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87chapter-1/</guid>
        <description>&lt;h1 id=&#34;量子纠缠的早期视角&#34;&gt;量子纠缠的早期视角
&lt;/h1&gt;
&lt;h2 id=&#34;epr佯谬&#34;&gt;EPR佯谬
&lt;/h2&gt;
&lt;h3 id=&#34;一般的纠缠态&#34;&gt;一般的纠缠态
&lt;/h3&gt;
&lt;p&gt;一个最经典的纠缠态的例子就是：在计算基矢 (Computational basis) 中，如果对于一个两个量子比特的系统（包含了两个子系统 Alice 和 Bob），总状态是：&lt;/p&gt;
&lt;p&gt;$$
\ket{\psi} = \frac{1}{\sqrt{2}}(\ket{0}\ket{1} + \ket{1}\ket{0})
$$&lt;/p&gt;
&lt;p&gt;其中 $\ket{0}\ket{1}$ 表示一个复合系统，等价于 $\ket{0} \otimes \ket{1}$，左边代表系统 I 的状态，右边表示系统 II 的状态。&lt;/p&gt;
&lt;p&gt;那么对于这个系统，如果测量到 A 系统的状态是 $\ket{0}$，那么 B 系统的状态就是 $\ket{1}$；另一种情况也是一样的，这个形式与式（8）具有相似之处。&lt;/p&gt;
&lt;p&gt;所谓“纠缠”就是：对一个系统的观测结果会&lt;strong&gt;瞬间影响&lt;/strong&gt;另一个系统的状态，而且&lt;strong&gt;这种影响是非局域性的&lt;/strong&gt;（无论两个系统相距多远），这就像一种“幽灵般的超距作用”。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;epr佯谬-1&#34;&gt;EPR佯谬
&lt;/h3&gt;
&lt;p&gt;对于纠缠这个概念，最早的启发来自 Einstein 与其合作者在 1935 年发表的论文：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?&amp;rdquo;&lt;br&gt;
—— 量子力学中对物理现实的描述是完整的吗？&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;他们认为量子力学的表述是不完备的，并提出了一个纠缠系统的思考实验。他们首先定义了“物理现实中的元素”（Elements of Physical Reality）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;定义：&lt;/strong&gt;&lt;br&gt;
如果我们可以在&lt;strong&gt;不干扰系统的前提下&lt;/strong&gt;，准确预测该系统中某一物理量的值，那么就存在一个物理现实的元素对应于这个物理量。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;然后他们将这个标准应用到一个复合量子系统：两个相距很远的粒子（编号为 1 和 2），其状态由如下纠缠波函数描述：&lt;/p&gt;
&lt;p&gt;$$
\psi(x_1, x_2, p_1, p_2) = \delta(x_1 - x_2 - L)\delta(p_1 + p_2)
$$&lt;/p&gt;
&lt;p&gt;其中 $\delta$ 并不是真正的 Dirac delta 函数，而是一个&lt;strong&gt;归一化的尖峰函数&lt;/strong&gt;；$L$ 是一个相对于粒子间相互作用而言非常大的距离。&lt;/p&gt;
&lt;p&gt;这个波函数的物理意义是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两个粒子之间的距离几乎是 $L$；&lt;/li&gt;
&lt;li&gt;总动量几乎为 $0$；&lt;/li&gt;
&lt;li&gt;而且 $x_1 - x_2$ 和 $p_1 + p_2$ 是可同时观测的对易算符。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;💡 注：你也可以在这里插入一个 delta 函数图像来辅助理解。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;对于这个状态来说，我们对单个粒子的状态（位置或动量）是一无所知的；我们只知道两个粒子之间的差值（距离、动量和）可以确定。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;如果我们测量粒子 1 的位置 $x_1$，我们可以准确预测粒子 2 的位置：$x_2 = x_1 - L$。&lt;br&gt;
根据 EPR 的论点：由于两个粒子此时&lt;strong&gt;不再相互作用&lt;/strong&gt;，粒子 1 的测量&lt;strong&gt;不会干扰&lt;/strong&gt;粒子 2，因此 $x_2$ 对应着一个物理现实元素。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同理，如果我们测量粒子 1 的动量 $p_1$，就能预测粒子 2 的动量：$p_2 = -p_1$，因此 $p_2$ 也对应一个物理现实元素。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是，根据量子力学的基本原理（不确定性原理）：&lt;/p&gt;
&lt;p&gt;$$
\Delta x \cdot \Delta p \geq \frac{\hbar}{2}
$$&lt;/p&gt;
&lt;p&gt;当粒子的位置被精确测量（$\Delta x = 0$）时，其动量的测量精度就必须变差（$\Delta p \to \infty$），所以&lt;strong&gt;不能同时确定位置与动量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;因此，EPR 论文指出：我们从测量粒子 1 就可以同时“知道”粒子 2 的位置和动量，这与量子力学的不确定性原理矛盾。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;🧠 结论：这说明量子力学对物理现实的描述是不完备的。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;EPR 因此推测：&lt;strong&gt;存在某些“隐藏变量”&lt;/strong&gt;（目前未知），使得这些物理量实际上是可以同时确定的。这就是“隐变量理论”（Hidden Variables Theory）的雏形。论文并未给出这种理论的构造，但为后来的 Bell 不等式与实验验证奠定了基础。&lt;/p&gt;
&lt;h2 id=&#34;附录&#34;&gt;附录
&lt;/h2&gt;
&lt;h3 id=&#34;参考文献&#34;&gt;参考文献
&lt;/h3&gt;
&lt;h3 id=&#34;版权信息&#34;&gt;版权信息
&lt;/h3&gt;
&lt;p&gt;本文原载于 &lt;a class=&#34;link&#34; href=&#34;https://quantum51.top&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;quantum51.top&lt;/a&gt;，遵循 CC BY-NC-SA 4.0 协议，复制请保留原文出处。&lt;/p&gt;
</description>
        </item>
        <item>
        <title></title>
        <link>http://localhost:1313/1/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://localhost:1313/1/</guid>
        <description>&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;###标题&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;slug&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;###描述&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;2025-04-19T09:34:28+08:00&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;lastmod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;2025-04-19T09:34:28+08:00&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;###背景图（最好是把图片放到文件夹内）&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;math&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;license&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hidden&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;draft&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;categories&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;###目录&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;###标签&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h1 id=&#34;一级标题&#34;&gt;一级标题
&lt;/h1&gt;
&lt;h2 id=&#34;二级标题&#34;&gt;二级标题
&lt;/h2&gt;
&lt;h3 id=&#34;三级标题&#34;&gt;三级标题
&lt;/h3&gt;
</description>
        </item>
        
    </channel>
</rss>
